{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekurencyjne Sieci Neuronowe (RNN)\n",
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane sekwencyjne\n",
    "\n",
    "Modele, którymi zajmowaliśmy się wcześniej zakładały konkretny kształt danych. Dla przykładu klasyczna sieć neuronowa fully-connected zakładała, że na wejściu dostanie wektory rozmiaru $784$ - dla wektorów o innej wymiarowości i innych obiektów model zwyczajnie nie będzie działać.\n",
    "\n",
    "Takie założenie bywa szczególnie niewygodne przy pracy z niektórymi typami danych, takimi jak:\n",
    "* językiem naturalny (zdania nie mają zadanej z góry liczby słów)\n",
    "* szeregi czasowe (dane giełdowe ciągną się właściwie w nieskończoność) \n",
    "* dźwięk (nagrania mogą być krótsze lub dłuższe).\n",
    "\n",
    "Do rozwiązania tego problemu służą rekuencyjne sieci neuronowe (*recurrent neural networks, RNNs*), które zapamiętują swój stan z poprzedniej iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie danych\n",
    "Na tych zajęciach będziemy traktować cyfry z MNISTa jako dane sekwencyjne, gdzie w danym kroku czasowym $T$ obserwujemy $T$-ty wiersz pikseli z cyfry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([ToTensor(), Lambda(lambda x: x.reshape(28, 28))])\n",
    "\n",
    "train_data = MNIST(root='.', train=True, transform=transforms, download=True)\n",
    "test_data = MNIST(root='.', train=False, transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1. (2 pkt.)\n",
    "\n",
    "Zaimplementuj \"zwykłą\" sieć rekurencyjną. \n",
    "![rnn](resources/rnn.png)\n",
    "\n",
    "* W klasie `RNN` należy zainicjalizować potrzebne wagi oraz zaimplementować główną logikę dla pojedynczej chwili czasowej $x_t$\n",
    "* Wyjście z sieci możemy mieć dowolny rozmiar, potrzebna jest również warstwa przekształacjąca stan ukryty na wyjście.\n",
    "* W pętli uczenia należy dodać odpowiednie wywołanie sieci. HINT: pamiętać o iterowaniu po wymiarze \"czasowym\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 hidden_size: int, \n",
    "                 output_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        :param output_size: int\n",
    "            Desired dimensionality of the output vector\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input_to_hidden = ??? \n",
    "        self.hidden_to_output = ???\n",
    "    \n",
    "    # for the sake of simlicity a single forward will process only a single timestamp \n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                hidden: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        :param hidden: torch.tensor\n",
    "            Representation of the memory of the RNN from previous timestep\n",
    "            shape [batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        combined = torch.cat([input, hidden], dim=1) \n",
    "        hidden = ???\n",
    "        output =  ???\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden state\n",
    "        \"\"\"\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.303147315979004\n",
      "Epoch: 0 Iter: 101/1200 Loss: 1.4431965351104736\n",
      "Epoch: 0 Iter: 201/1200 Loss: 1.0521228313446045\n",
      "Epoch: 0 Iter: 301/1200 Loss: 1.4707446098327637\n",
      "Epoch: 0 Iter: 401/1200 Loss: 0.8529232144355774\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.7187938094139099\n",
      "Epoch: 0 Iter: 601/1200 Loss: 0.8162944316864014\n",
      "Epoch: 0 Iter: 701/1200 Loss: 1.1790978908538818\n",
      "Epoch: 0 Iter: 801/1200 Loss: 1.7470533847808838\n",
      "Epoch: 0 Iter: 901/1200 Loss: 0.9846989512443542\n",
      "Epoch: 0 Iter: 1001/1200 Loss: 1.5445022583007812\n",
      "Epoch: 0 Iter: 1101/1200 Loss: 1.795793056488037\n",
      "Final Accuracy: 0.5093\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize network and optimizer\n",
    "rnn = RNN(28, 64, 10)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)   \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epochs = 1\n",
    "\n",
    "# main loop\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # get initial hidden state\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the 2nd, time dimensiotn\n",
    "        \n",
    "        # YOUR CODE HERE \n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        output = ???\n",
    "            \n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        if i % 100 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        seq_len = x.shape[1]\n",
    "        output = ???\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "\n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.4, \"Subject to random seed you should get over 0.4 accuracy, try changing the seed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "Dopisz kod do powyższej pętli, który zbiera gradienty po kolejnych stanach ukrytych dla przykładu. Spójrz na wykres przedstawiający normy kolejnych gradientów i spróbuj zinterpretować wyniki, które widzisz. \n",
    "\n",
    "**Hint implementacyjny**: dla MNISTa mamy 28 kroków (więc 28 norm gradientów dla każdego przykładu).  \n",
    "\n",
    "**Ważne:** Ponieważ normalnie w torchu czyścimy wszystkie gradienty po każdej iteracji aby je zachować w dla niektórych wag przydatna będzie metoda [`retain_grad`](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.retain_grad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 28 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean_grads in assume to be a 1D array or list of average gradients norm per timestep memory \n",
    "mean_grads = ???\n",
    "\n",
    "plt.bar(x=np.arange(len(mean_grads)), height=mean_grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Ostatnim zadaniem jest implementacji komórki i sieci LSTM. \n",
    "\n",
    "![lstm](resources/lstm.png)\n",
    "\n",
    "* W klasie `LSTMCell` ma znaleźć się główna loginka LSTMa, czyli wszystkie wagi do stanów `hidden` i `cell` jak i bramek kontrolujących te stany. \n",
    "* W klasie `LSTM` powinno znaleźć się wywołanie komórki LSTM, HINT: poprzednio było w pętli uczenia, teraz przenisiemy to do klasy modelu.\n",
    "* W pętli uczenia należy uzupełnić brakujące wywołania do uczenia i ewaluacji modelu.\n",
    "\n",
    "Zdecydowanie polecam [materiały Chrisa Olaha](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) do zarówno zrozumienia jak i ściągi do wzorów.\n",
    "\n",
    "Zadaniem jest osiągnięcie dokładności na poziomie przynajmniej 90%, przy prawidłowej implementacji nie powinno być z tym problemów używając podanych hiperparametrów. Dozwolona jest oczywiście zmiana `random seed`.\n",
    "\n",
    "#### Komórka LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTMCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # initialize LSTM weights \n",
    "        # NOTE: there are different approaches that are all correct \n",
    "        # (e.g. single matrix for all input opperations), you can pick\n",
    "        # whichever you like for this task\n",
    "    \n",
    "        ???\n",
    "\n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                states: Tuple[torch.tensor, torch.tensor]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \n",
    "        hidden, cell = states\n",
    "        \n",
    "        # Compute input, forget, and output gates\n",
    "        # then compute new cell state and hidden state\n",
    "        # see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        \n",
    "        cell = ???\n",
    "        \n",
    "        hidden = ???\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasa modelu LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.cell = LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "        \n",
    "    def forward(self, \n",
    "                input: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        Returns Tuple of two torch.tensors, both of shape [seq_len, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        initial_states = self.init_hidden_cell(batch_size)\n",
    "        \n",
    "        hiddens = []\n",
    "        cells = []\n",
    "        \n",
    "        hidden, cell = initial_states\n",
    "\n",
    "        # this time we will process the whole sequence in the forward method\n",
    "        # as oppose to the previous exercise, remember to loop over the timesteps\n",
    "        \n",
    "        time_steps = input.shape[1]\n",
    "        \n",
    "        \n",
    "        hiddens = ???\n",
    "        cells = ???\n",
    "\n",
    "        return hiddens, cells\n",
    "    \n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden and cell states\n",
    "        \"\"\"\n",
    "        return (torch.zeros(batch_size, self.hidden_size, requires_grad=True), \n",
    "                torch.zeros(batch_size, self.hidden_size, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.3939\n",
      "Epoch: 0 Iter: 51/1200 Loss: 2.1830\n",
      "Epoch: 0 Iter: 101/1200 Loss: 1.6664\n",
      "Epoch: 0 Iter: 151/1200 Loss: 1.4374\n",
      "Epoch: 0 Iter: 201/1200 Loss: 1.4193\n",
      "Epoch: 0 Iter: 251/1200 Loss: 1.2045\n",
      "Epoch: 0 Iter: 301/1200 Loss: 0.9174\n",
      "Epoch: 0 Iter: 351/1200 Loss: 1.0483\n",
      "Epoch: 0 Iter: 401/1200 Loss: 1.0119\n",
      "Epoch: 0 Iter: 451/1200 Loss: 0.6014\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.6967\n",
      "Epoch: 0 Iter: 551/1200 Loss: 0.3628\n",
      "Epoch: 0 Iter: 601/1200 Loss: 0.5102\n",
      "Epoch: 0 Iter: 651/1200 Loss: 0.4934\n",
      "Epoch: 0 Iter: 701/1200 Loss: 0.6267\n",
      "Epoch: 0 Iter: 751/1200 Loss: 0.3685\n",
      "Epoch: 0 Iter: 801/1200 Loss: 0.3376\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize the lstm with an additional cliassifier layer at the top\n",
    "lstm = LSTM(input_size=28, hidden_size=64)\n",
    "clf = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "# initialize a optimizer\n",
    "params = chain(lstm.parameters(), clf.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.01) \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epoch = 1\n",
    "\n",
    "# main loop\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the sequence length here\n",
    "        \n",
    "        output = ???\n",
    "        # calucate the loss\n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        \n",
    "        if i % 50 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss:.4f}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        output = ???\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "    \n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.9, \"Subject to random seed you should get over 0.9 accuracy, try changing the seed!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
