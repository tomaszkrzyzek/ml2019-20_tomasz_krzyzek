{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekurencyjne Sieci Neuronowe (RNN)\n",
    "### Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane sekwencyjne\n",
    "\n",
    "Modele, którymi zajmowaliśmy się wcześniej zakładały konkretny kształt danych. Dla przykładu klasyczna sieć neuronowa fully-connected zakładała, że na wejściu dostanie wektory rozmiaru $784$ - dla wektorów o innej wymiarowości i innych obiektów model zwyczajnie nie będzie działać.\n",
    "\n",
    "Takie założenie bywa szczególnie niewygodne przy pracy z niektórymi typami danych, takimi jak:\n",
    "* językiem naturalny (zdania nie mają zadanej z góry liczby słów)\n",
    "* szeregi czasowe (dane giełdowe ciągną się właściwie w nieskończoność) \n",
    "* dźwięk (nagrania mogą być krótsze lub dłuższe).\n",
    "\n",
    "Do rozwiązania tego problemu służą rekuencyjne sieci neuronowe (*recurrent neural networks, RNNs*), które zapamiętują swój stan z poprzedniej iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ładowanie danych\n",
    "Na tych zajęciach będziemy traktować cyfry z MNISTa jako dane sekwencyjne, gdzie w danym kroku czasowym $T$ obserwujemy $T$-ty wiersz pikseli z cyfry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([ToTensor(), Lambda(lambda x: x.reshape(28, 28))])\n",
    "\n",
    "train_data = MNIST(root='.', train=True, transform=transforms, download=True)\n",
    "test_data = MNIST(root='.', train=False, transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1. (2 pkt.)\n",
    "\n",
    "Zaimplementuj \"zwykłą\" sieć rekurencyjną. \n",
    "![rnn](resources/rnn.png)\n",
    "\n",
    "* W klasie `RNN` należy zainicjalizować potrzebne wagi oraz zaimplementować główną logikę dla pojedynczej chwili czasowej $x_t$\n",
    "* Wyjście z sieci możemy mieć dowolny rozmiar, potrzebna jest również warstwa przekształacjąca stan ukryty na wyjście.\n",
    "* W pętli uczenia należy dodać odpowiednie wywołanie sieci. HINT: pamiętać o iterowaniu po wymiarze \"czasowym\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 hidden_size: int, \n",
    "                 output_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        :param output_size: int\n",
    "            Desired dimensionality of the output vector\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.input_to_hidden = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.hidden_to_output = torch.nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    # for the sake of simlicity a single forward will process only a single timestamp \n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                hidden: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        :param hidden: torch.tensor\n",
    "            Representation of the memory of the RNN from previous timestep\n",
    "            shape [batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        hidden = self.activation(self.input_to_hidden(torch.cat((input, hidden), 1)))\n",
    "        output = self.hidden_to_output(hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden state\n",
    "        \"\"\"\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.305149555206299\n",
      "Epoch: 0 Iter: 101/1200 Loss: 1.415971040725708\n",
      "Epoch: 0 Iter: 201/1200 Loss: 1.1278998851776123\n",
      "Epoch: 0 Iter: 301/1200 Loss: 1.377793550491333\n",
      "Epoch: 0 Iter: 401/1200 Loss: 2.948476791381836\n",
      "Epoch: 0 Iter: 501/1200 Loss: 1.3538953065872192\n",
      "Epoch: 0 Iter: 601/1200 Loss: 1.1732196807861328\n",
      "Epoch: 0 Iter: 701/1200 Loss: 1.1365710496902466\n",
      "Epoch: 0 Iter: 801/1200 Loss: 0.8093414902687073\n",
      "Epoch: 0 Iter: 901/1200 Loss: 1.2751113176345825\n",
      "Epoch: 0 Iter: 1001/1200 Loss: 2.1797962188720703\n",
      "Epoch: 0 Iter: 1101/1200 Loss: 1.420640468597412\n",
      "Final Accuracy: 0.5072\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(187675337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize network and optimizer\n",
    "rnn = RNN(28, 64, 10)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)   \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epochs = 1\n",
    "\n",
    "# main loop\n",
    "grads = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):  \n",
    "        optimizer.zero_grad()\n",
    "        # get initial hidden state\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "\n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the 2nd, time dimensiotn\n",
    "        \n",
    "        seq_len = x.shape[1]\n",
    "            \n",
    "        hiddens = []\n",
    "        output = torch.zeros((x.shape[0]))\n",
    "        for el in range(seq_len):\n",
    "            output, hidden = rnn.forward(x[:, el], hidden)\n",
    "            hidden.retain_grad()\n",
    "            hiddens.append(hidden)\n",
    "            \n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        \n",
    "        grads.append([np.linalg.norm(h.grad.numpy()) for h in hiddens])\n",
    "        \n",
    "        if i % 100 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "\n",
    "        hidden = rnn.init_hidden(x.shape[0])\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        output = torch.Tensor((x.shape[0]))\n",
    "        for el in range(seq_len):\n",
    "            output, hidden = rnn.forward(x[:, el], hidden)\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "\n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.4, \"Subject to random seed you should get over 0.4 accuracy, try changing the seed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "Dopisz kod do powyższej pętli, który zbiera gradienty po kolejnych stanach ukrytych dla przykładu. Spójrz na wykres przedstawiający normy kolejnych gradientów i spróbuj zinterpretować wyniki, które widzisz. \n",
    "\n",
    "**Hint implementacyjny**: dla MNISTa mamy 28 kroków (więc 28 norm gradientów dla każdego przykładu).  \n",
    "\n",
    "**Ważne:** Ponieważ normalnie w torchu czyścimy wszystkie gradienty po każdej iteracji aby je zachować w dla niektórych wag przydatna będzie metoda [`retain_grad`](https://pytorch.org/docs/stable/autograd.html#torch.Tensor.retain_grad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 28 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean_grads in assume to be a 1D array or list of average gradients norm per timestep memory \n",
    "grads = np.asarray(grads)\n",
    "mean_grads = np.mean(grads, axis=0)\n",
    "\n",
    "plt.bar(x=np.arange(len(mean_grads)), height=mean_grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Ostatnim zadaniem jest implementacji komórki i sieci LSTM. \n",
    "\n",
    "![lstm](resources/lstm.png)\n",
    "\n",
    "* W klasie `LSTMCell` ma znaleźć się główna loginka LSTMa, czyli wszystkie wagi do stanów `hidden` i `cell` jak i bramek kontrolujących te stany. \n",
    "* W klasie `LSTM` powinno znaleźć się wywołanie komórki LSTM, HINT: poprzednio było w pętli uczenia, teraz przenisiemy to do klasy modelu.\n",
    "* W pętli uczenia należy uzupełnić brakujące wywołania do uczenia i ewaluacji modelu.\n",
    "\n",
    "Zdecydowanie polecam [materiały Chrisa Olaha](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) do zarówno zrozumienia jak i ściągi do wzorów.\n",
    "\n",
    "Zadaniem jest osiągnięcie dokładności na poziomie przynajmniej 90%, przy prawidłowej implementacji nie powinno być z tym problemów używając podanych hiperparametrów. Dozwolona jest oczywiście zmiana `random seed`.\n",
    "\n",
    "#### Komórka LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTMCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # initialize LSTM weights \n",
    "        # NOTE: there are different approaches that are all correct \n",
    "        # (e.g. single matrix for all input opperations), you can pick\n",
    "        # whichever you like for this task\n",
    "    \n",
    "        self.forget_linear = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.forget_sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.input_gate_linear = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_gate_sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.input_linear = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_tanh = torch.nn.Tanh()\n",
    "        \n",
    "        self.output_linear = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.output_sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        self.output_tanh = torch.nn.Tanh()\n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "                input: torch.tensor, \n",
    "                states: Tuple[torch.tensor, torch.tensor]) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \n",
    "        hidden, cell = states\n",
    "        \n",
    "        # Compute input, forget, and output gates\n",
    "        # then compute new cell state and hidden state\n",
    "        # see http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "        \n",
    "        h_i = torch.cat((hidden, input), 1)\n",
    "        \n",
    "        cell = self.forget_sigmoid(self.forget_linear(h_i)) * cell \\\n",
    "               + self.input_gate_sigmoid(self.input_gate_linear(h_i)) * self.input_tanh(self.input_linear(h_i))\n",
    "\n",
    "        hidden = self.output_tanh(cell) * self.output_sigmoid(self.output_linear(h_i))\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasa modelu LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size: int, \n",
    "                 hidden_size: int):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "            Dimensionality of the input vector\n",
    "        :param hidden_size: int\n",
    "            Dimensionality of the hidden space\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.cell = LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "        \n",
    "    def forward(self, \n",
    "                input: torch.tensor) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"\n",
    "        :param input: torch.tensor \n",
    "            Input tesnor for a single observation at timestep t\n",
    "            shape [batch_size, input_size]\n",
    "        Returns Tuple of two torch.tensors, both of shape [seq_len, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        \n",
    "        initial_states = self.init_hidden_cell(batch_size)\n",
    "        \n",
    "        hiddens = []\n",
    "        cells = []\n",
    "        \n",
    "        hidden, cell = initial_states\n",
    "\n",
    "        # this time we will process the whole sequence in the forward method\n",
    "        # as oppose to the previous exercise, remember to loop over the timesteps\n",
    "        \n",
    "        seq_len = input.shape[1]\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            hidden, cell = self.cell.forward(input[:, i], (hidden, cell))\n",
    "            hiddens.append(hidden)\n",
    "            cells.append(cell)\n",
    "        \n",
    "        return hiddens, cells\n",
    "    \n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        \"\"\"\n",
    "        Returns initial value for the hidden and cell states\n",
    "        \"\"\"\n",
    "        return (torch.zeros(batch_size, self.hidden_size, requires_grad=True), \n",
    "                torch.zeros(batch_size, self.hidden_size, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pętla uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iter: 1/1200 Loss: 2.3071\n",
      "Epoch: 0 Iter: 51/1200 Loss: 0.8275\n",
      "Epoch: 0 Iter: 101/1200 Loss: 0.8636\n",
      "Epoch: 0 Iter: 151/1200 Loss: 0.6607\n",
      "Epoch: 0 Iter: 201/1200 Loss: 0.3896\n",
      "Epoch: 0 Iter: 251/1200 Loss: 0.4597\n",
      "Epoch: 0 Iter: 301/1200 Loss: 0.2418\n",
      "Epoch: 0 Iter: 351/1200 Loss: 0.4081\n",
      "Epoch: 0 Iter: 401/1200 Loss: 0.4223\n",
      "Epoch: 0 Iter: 451/1200 Loss: 0.3197\n",
      "Epoch: 0 Iter: 501/1200 Loss: 0.1321\n",
      "Epoch: 0 Iter: 551/1200 Loss: 0.4428\n",
      "Epoch: 0 Iter: 601/1200 Loss: 0.3683\n",
      "Epoch: 0 Iter: 651/1200 Loss: 0.4195\n",
      "Epoch: 0 Iter: 701/1200 Loss: 0.1292\n",
      "Epoch: 0 Iter: 751/1200 Loss: 0.0769\n",
      "Epoch: 0 Iter: 801/1200 Loss: 0.0810\n",
      "Epoch: 0 Iter: 851/1200 Loss: 0.2988\n",
      "Epoch: 0 Iter: 901/1200 Loss: 0.3743\n",
      "Epoch: 0 Iter: 951/1200 Loss: 0.1743\n",
      "Epoch: 0 Iter: 1001/1200 Loss: 0.0217\n",
      "Epoch: 0 Iter: 1051/1200 Loss: 0.0797\n",
      "Epoch: 0 Iter: 1101/1200 Loss: 0.1802\n",
      "Epoch: 0 Iter: 1151/1200 Loss: 0.0570\n",
      "Final Accuracy: 0.9715\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "# build data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# initialize the lstm with an additional cliassifier layer at the top\n",
    "lstm = LSTM(input_size=28, hidden_size=64)\n",
    "clf = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "# initialize a optimizer\n",
    "params = chain(lstm.parameters(), clf.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.01) \n",
    "\n",
    "# we will train for only a single epoch \n",
    "epoch = 1\n",
    "\n",
    "# main loop\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader):        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get output for the sample, remember that we treat it as a sequence\n",
    "        # so you need to iterate over the sequence length here <-- ???\n",
    "        \n",
    "        output = clf(lstm.forward(x)[0][-1])\n",
    "        \n",
    "        # calucate the loss\n",
    "        loss = cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()                                \n",
    "        \n",
    "        if i % 50 == 1:\n",
    "            print(f\"Epoch: {epoch} Iter: {i}/{len(train_loader)} Loss: {loss:.4f}\")\n",
    "\n",
    "# evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        \n",
    "        output = clf(lstm.forward(x)[0][-1])\n",
    "\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += int(sum(pred == y))\n",
    "    \n",
    "    accuracy = correct / (batch_size * len(test_loader))\n",
    "    \n",
    "    print(f\"Final Accuracy: {accuracy}\")\n",
    "    assert accuracy > 0.9, \"Subject to random seed you should get over 0.9 accuracy, try changing the seed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
