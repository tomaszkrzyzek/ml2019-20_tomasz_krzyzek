{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ćwiczenia 6. Walidacja Krzyżowa\n",
    "\n",
    "## PyTorch na następne ćwiczenia.\n",
    "\n",
    "Proszę zainstalować pakiet [PyTorch](https://pytorch.org/) oraz torchvision na kolejne zajęcia. Jeśli używane, mając swoje środowisko aktywne użyć:\n",
    "\n",
    " * GPU: `conda install pytorch torchvision cudatoolkit=9.0 -c pytorch`\n",
    " * tylko CPU: `conda install pytorch torchvision cpuonly  -c pytorch`\n",
    "\n",
    "## Klasyfikacja\n",
    "\n",
    "Dzisiaj na zajęciach zajmiemy się problemem klasyfikacji. Podobnie do regresji liniowej jest to przykład uczenia nadzorowanego, ale zamiast przewidywać konkretną liczbę dla danej obserwacji, przewidujemy jego przynajeżność do jednej z *k* klas. Na tych zajęciach będziemy rozważać klasyfikacje binarną, czyli uczyć modele odpowiadające funkcji:\n",
    "\n",
    "$$ f(x) = y, \\quad y \\in \\{0,1\\} $$\n",
    "\n",
    "Poniżej ładowane są dane, do razu już podzielone na dwie części."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import get_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.1 (0.5 pkt.)\n",
    "\n",
    "Używając modelu [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) z pakietu sklearn uzyskać 100% dokładność (mierzoną miarą [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html))na zbiorze treningowym. Państwa zadanie polega na dobraniu parametru `gamma`, dla ułatwienia proszę nie zmieniać pozostałych domyślnych parametrów. Zalecany przedział parametru `gamma` to wartości z przedziału [0, 1] w skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "gamma = 1\n",
    "\n",
    "svm = SVC(gamma=gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = 1\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "train_acc = svm.score(X_train, y_train)\n",
    "\n",
    "assert train_acc == 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1.2 (0.5 pkt.)\n",
    "Używając tej samej rodziny modeli znajdź tym razem taką wartość `gamma`, która daje najlepszy wynik na zbiorze **testowym**. Powinieneś(-aś) być w stanie osiągnąć wynik co najmniej `0.95` accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-10, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 1e-10, score: 0.6223776223776224\n",
      "gamma: 1.67683293681101e-10, score: 0.6223776223776224\n",
      "gamma: 2.811768697974225e-10, score: 0.6223776223776224\n",
      "gamma: 4.71486636345739e-10, score: 0.6223776223776224\n",
      "gamma: 7.906043210907701e-10, score: 0.6223776223776224\n",
      "gamma: 1.3257113655901108e-09, score: 0.6293706293706294\n",
      "gamma: 2.222996482526191e-09, score: 0.6923076923076923\n",
      "gamma: 3.727593720314938e-09, score: 0.7692307692307693\n",
      "gamma: 6.250551925273976e-09, score: 0.8251748251748252\n",
      "gamma: 1.0481131341546852e-08, score: 0.8671328671328671\n",
      "gamma: 1.7575106248547893e-08, score: 0.8881118881118881\n",
      "gamma: 2.9470517025518096e-08, score: 0.8881118881118881\n",
      "gamma: 4.9417133613238385e-08, score: 0.9230769230769231\n",
      "gamma: 8.286427728546843e-08, score: 0.9370629370629371\n",
      "gamma: 1.389495494373136e-07, score: 0.9370629370629371\n",
      "gamma: 2.329951810515372e-07, score: 0.9370629370629371\n",
      "gamma: 3.906939937054621e-07, score: 0.9440559440559441\n",
      "gamma: 6.55128556859551e-07, score: 0.951048951048951\n",
      "gamma: 1.0985411419875572e-06, score: 0.951048951048951\n",
      "gamma: 1.8420699693267164e-06, score: 0.951048951048951\n",
      "gamma: 3.0888435964774785e-06, score: 0.951048951048951\n",
      "gamma: 5.179474679231212e-06, score: 0.951048951048951\n",
      "gamma: 8.68511373751352e-06, score: 0.951048951048951\n",
      "gamma: 1.4563484775012445e-05, score: 0.951048951048951\n",
      "gamma: 2.4420530945486497e-05, score: 0.965034965034965\n",
      "gamma: 4.094915062380427e-05, score: 0.958041958041958\n",
      "gamma: 6.866488450042999e-05, score: 0.972027972027972\n",
      "gamma: 0.00011513953993264481, score: 0.965034965034965\n",
      "gamma: 0.00019306977288832496, score: 0.965034965034965\n",
      "gamma: 0.00032374575428176466, score: 0.951048951048951\n",
      "gamma: 0.0005428675439323859, score: 0.9370629370629371\n",
      "gamma: 0.0009102981779915227, score: 0.9300699300699301\n",
      "gamma: 0.0015264179671752333, score: 0.9090909090909091\n",
      "gamma: 0.0025595479226995332, score: 0.9090909090909091\n",
      "gamma: 0.004291934260128779, score: 0.9020979020979021\n",
      "gamma: 0.007196856730011514, score: 0.6153846153846154\n",
      "gamma: 0.012067926406393264, score: 0.6223776223776224\n",
      "gamma: 0.020235896477251554, score: 0.6223776223776224\n",
      "gamma: 0.0339322177189533, score: 0.6223776223776224\n",
      "gamma: 0.05689866029018305, score: 0.6223776223776224\n",
      "gamma: 0.09540954763499924, score: 0.6223776223776224\n",
      "gamma: 0.15998587196060574, score: 0.6223776223776224\n",
      "gamma: 0.26826957952797276, score: 0.6223776223776224\n",
      "gamma: 0.4498432668969453, score: 0.6223776223776224\n",
      "gamma: 0.7543120063354607, score: 0.6223776223776224\n",
      "gamma: 1.2648552168552958, score: 0.6223776223776224\n",
      "gamma: 2.1209508879201926, score: 0.6223776223776224\n",
      "gamma: 3.556480306223136, score: 0.6223776223776224\n",
      "gamma: 5.963623316594637, score: 0.6223776223776224\n",
      "gamma: 10.0, score: 0.6223776223776224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "for gamma in np.logspace(-10, 1):\n",
    "    svm = SVC(gamma=gamma)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print(f'gamma: {gamma}, score: {svm.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "best_gamma = 6.866488450042999e-05\n",
    "\n",
    "svm = SVC(gamma=best_gamma)\n",
    "svm.fit(X_train, y_train)\n",
    "test_acc = svm.score(X_test, y_test)\n",
    "\n",
    "assert test_acc >= 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "**W poprzednim zadaniu zakładaliśmy, że podział na zbiór trenujący/testujący jest nam podany z góry, ale co jeśli go nie mamy?**\n",
    "\n",
    "Możemy oczywiście sami arbitralnie wybrać część datasetu i uznać ją za nasz zbiór testowy, ale to mogą się z tym wiązać dodatkowe problemy: co jeśli wybrany przez nas fragment jest akurat różny od reszty datasetu, lub odwrotnie?\n",
    "\n",
    "**Rozwiązanie:** Walidacja Krzyżowa.\n",
    "\n",
    "1. Podziel dataset na zadaną przez parametr `k` liczbę (prawie) równych grup.\n",
    "2. Dla każdego podziału, zwróć jedną z tych części jako zbiór testowy, a sumę reszty jako zbiór treningowy.\n",
    "3. Po nauczeniu łącznie `k` modeli, uśrednij ich wyniki na zbiorach testowych i zwróć jako ostateczny wynik.\n",
    "\n",
    "## Zadanie 2. (2 pkt.)\n",
    "\n",
    "Państwa zadaniem jest zaimplementowanie walidacji krzyżowej, czyli funkcji, która dla podanego datasetu w postaci macierzy danych `X` i wektora etykiet `y` zwróci listę `k` krotek: \n",
    "  \n",
    "  `(treningowe_dane, treningowe_etykiety, testowe_dane, testowe_etykiety)`\n",
    "  \n",
    "podziałów dokonanych przez walidację krzyżową. Następnie należy użyć modelu z poprzedniego zadania dla policzenia dokładności na zbiorze testowym dla walidacji krzyżowej.\n",
    "\n",
    "Proszę **nie** korzystać z gotowych rozwiązań dostępnych w pakiecie sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def cross_validation(X: np.ndarray, y: np.ndarray, k: int) -> List[Tuple[np.ndarray, np.ndarray, \n",
    "                                                                         np.ndarray, np.ndarray]]:\n",
    "    \n",
    "    res = []\n",
    "    N = len(X)\n",
    "    \n",
    "    fold_len = np.full(k, N // k, dtype=np.int)\n",
    "    fold_len[:N % k] += 1\n",
    "    \n",
    "    for i in range(k):\n",
    "        X_train, y_train = [], []\n",
    "        current = 0\n",
    "        for j, length in enumerate(fold_len):\n",
    "            start, stop = current, current + length\n",
    "            if j == i:\n",
    "                X_test = X[start:stop]\n",
    "                y_test = y[start:stop]\n",
    "            else:\n",
    "                X_train += list(X[start:stop])\n",
    "                y_train += list(y[start:stop])\n",
    "            current = stop\n",
    "        res.append((np.array(X_train), np.array(y_train), X_test, y_test))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checker import test_cv\n",
    "\n",
    "test_cv(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924437199192672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_data(split=False)\n",
    "\n",
    "acc = []\n",
    "for X_train, y_train, X_test, y_test in cross_validation(X, y, k=5):\n",
    "    acc.append(svm.fit(X_train, y_train).score(X_test, y_test))\n",
    "    \n",
    "cv_accuracy = np.asarray(acc).mean()\n",
    "cv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (1 pkt.)\n",
    "\n",
    "Mając już lepszą metodę walidacji naszego rozwiązania Państwa zadaniem jest znalezienia najlepszego zestawu hiperparametrów dla modelu z poprzednich zadań, lecz tym razem będziemy szukać również parametru `C`. Parametru C zaleca się szukać w przedziale $(0, + \\infty)$ również w skali logarytmicznej.\n",
    "\n",
    "W zadaniu należy oczywiście skorzystać z zaimplementowanej przez Państwa walidacji krzyżowej. Ponieważ dla dwóch parametrów `C` oraz `gamma` możliwych kombinacji do przetestowania robi są dość sporo dla przetestowania dużych zakresów zalecane są również inne metody przeszukiwania, takie jak:\n",
    "\n",
    "* przeszukiwanie po kolei z jednym z parametrów ustalonym na stałą.\n",
    "* przeszukiwanie losowe obu parametrów\n",
    "\n",
    "Oczywiście jeśli zasoby na to pozwalają można szukać tzw. \"grid searchem\".\n",
    "\n",
    "Powinno udać się Państwu wyciągnąć przynajmniej `0.94` accuracy na walidacji krzyżowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:34<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.179474679231212e-06 1000.0 0.9542928116752059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "best_gamma, best_C, best_acc = 0, 0, 0\n",
    "for gamma in tqdm(np.logspace(-10, 1)):\n",
    "    for C in np.logspace(-10, 3):\n",
    "        acc = []\n",
    "        for X_train, y_train, X_test, y_test in cross_validation(X, y, k=5):\n",
    "            svm = SVC(C=C, gamma=gamma)\n",
    "            acc.append(svm.fit(X_train, y_train).score(X_test, y_test))\n",
    "        cv_accuracy = np.asarray(acc).mean()\n",
    "        if cv_accuracy > best_acc:\n",
    "            best_gamma = gamma\n",
    "            best_C = C\n",
    "            best_acc = cv_accuracy\n",
    "print(best_gamma, best_C, best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4. (3 punkty)\n",
    "\n",
    "Załóżmy, że naszym problemem jest zdecydowanie, która rodzina modeli *SVM* najlepiej radzi sobei z naszym datasetem. Przez rodzinę rozumiemy tutaj modele SVM z różną *funkcją bazwoą* (zwaną często *funkcją jądra*). W pakiecie mamy dostępne kilka możliwości, włącznie z podawaniem swoich własnych, ale w tym zadaniu skupimy się na czterech dostępnych od ręki: `linear`, `poly`, `rbf`, `sigmoid`.\n",
    "\n",
    "Wiemy jak znaleźć najlepszy zestaw parametrów dla danej rodziny modeli, zrobiliśmy to do tej pory dla domyślnej funkcji bazowej czyli `rbf`. Jak jednak mamy \"uczciwie\" porównać wyniki modeli pomiędzy sobą? Do tej pory patrzyliśmy na wyniki modelu dla datasetu testowego i to na podstawie tego wyniku wybieraliśmy najlepsze hiperparametry. Jakie mogą być z tym problemy? Overfitting?\n",
    "\n",
    "Rozwiązanie: jeszcze jedna walidacja krzyżowa!\n",
    "\n",
    "1. Pierwsza walidacja krzyżowa podzieli nam nasz zbiór na treningowy i testowy. Te testowe zbiory będą naszymi ostatecznymi zbiorami testowymi, na których nie będziemy w żaden sposób się uczyć czy szukać hiperparametrów. \n",
    "2. Następnie nasz zbiór treningowy podzielimy ponownie walidacją krzyżową na dwie części: faktyczny treningowy i walidacyjny. Tych dwóch podziałów będziemy używać jak poprzednio do uczenia modelu i testowania hiperparametrów.\n",
    "3. Po znalezieniu najlepszego zestawu hiperparametrów nauczymy ostatecznie nasz model na sumie zbiorów treningowego i walidacyjnego i sprawdzimy jego dokładność na ostatecznym zbiorze testowym.\n",
    "\n",
    "\n",
    "**Uwaga**: parametr `C` używany jest dla każdej możliwej funkcji bazowej. Proszę sprawdzić jakie parametry są używane dla jakich funkcji jądra. \n",
    "**Hint**: parametry, które mogą państwa interesować to oczywiście `kernel`, oraz `C`, `degree`, `gamma`, `coef0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [00:05<00:10,  5.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [00:12<00:06,  6.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:17<00:51, 17.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 111.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 126.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [00:00<00:00, 77.07it/s]A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [00:17<00:00,  4.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 1/2 [00:17<00:17, 17.33s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "X, y = get_data(split=False)\n",
    "\n",
    "test_acc = []\n",
    "for X_train_outer, y_train_outer, X_test_outer, y_test_outer in cross_validation(X, y, k=3):\n",
    "    best_kernel, best_C, best_acc = '', 0, 0\n",
    "    for C in tqdm(np.logspace(1, 10, num=10)):\n",
    "        for kernel in tqdm(['linear', 'poly', 'rbf', 'sigmoid']):\n",
    "            acc = []\n",
    "            for X_train, y_train, X_test, y_test in tqdm(cross_validation(X_train_outer, y_train_outer, k=3)):\n",
    "                svm = SVC(C=C, kernel=kernel, gamma='scale')\n",
    "                acc.append(svm.fit(X_train, y_train).score(X_test, y_test))\n",
    "            cv_accuracy = np.asarray(acc).mean()\n",
    "            if cv_accuracy > best_acc:\n",
    "                best_C = C\n",
    "                best_acc = cv_accuracy\n",
    "                best_kernel = kernel\n",
    "    svm = SVC(C=best_C, kernel=best_kernel, gamma='scale')\n",
    "    test_acc.append(svm.fit(X_train_outer, y_train_outer).score(X_test_outer, y_test_outer))\n",
    "print(np.asarray(test_acc).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
